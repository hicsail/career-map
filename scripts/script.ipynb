{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the links in datasheet at https://docs.google.com/spreadsheets/d/1N8XS6K7qgA8eem3skv4aIyV7NfcKv5C2FOOccXxboVc/edit#gid=1182321804"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint \n",
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "import re\n",
    "\n",
    "row_filter_mapping = {\n",
    "    3: 'State ILP',\n",
    "    4: 'ILP Webpage',\n",
    "    5: 'ILP Contact Name + Email',\n",
    "    6: 'ILP Policy',\n",
    "    7: 'ILP Guide',\n",
    "    8: 'State K12 Equity Plan',\n",
    "    9: 'State ESSA Plan',\n",
    "    10: 'ILP Equity Reference',\n",
    "    11: 'ILP Funding',\n",
    "    12: 'ILP PD/Training',\n",
    "    13: 'ILP Standards',\n",
    "    14: 'ILP Curriculum &/or Lessons',\n",
    "    15: 'ILP Tech Platform',\n",
    "    16: 'State SEL Webpage',\n",
    "    17: 'SEL in ILP Reference',\n",
    "    18: 'State Perkins V Plan',\n",
    "    19: 'K12 CTE',\n",
    "    20: 'K12 CTE, Career Pathways in ILP Reference',\n",
    "    21: 'Dual Enrollment Webpage',\n",
    "    22: 'IRC Webpage',\n",
    "    23: 'WBL Webpage', \n",
    "    24: 'WBL Guide',\n",
    "}\n",
    "\n",
    "strings_to_be_removed = ['Filter1', 'Filter2', 'Filter3', 'Subfilter 1a', \n",
    "                         'Subfilter 1b', 'Subfilter 2a', 'Subfilter 2b', 'Subfilter 2c', \n",
    "                         'Subfilter 3a','Subfilter 3b','Subfilter 3c','Subfilter 3d','Subfilter 3e', 'ILP Name + (Abbreviation)',\n",
    "                         'WBL Guide LINK', 'WBL Webpage LINK', 'IRC Webpage LINK', 'Dual Enrollment Webpage LINK', \n",
    "                         'K12 CTE &/or Career Pathways in ILP reference LINK', 'K12 CTE LINK', 'State CPV Plan LINK',\n",
    "                        'SEL in ILP reference LINK', 'SEL Webpage LINK', 'ILP Tech Platform Name w/LINK', 'ILP Curriculum &/or Lessons LINK',\n",
    "                        'ILP Standards LINK', 'ILP PD/Training LINK', 'Dedicated funding reference LINK', 'ILP equity reference LINK',\n",
    "                        'LINK to the state ESSA Plan', 'LINK to State K12 Equity Plan or Webpage', 'ILP Guide LINK',\n",
    "                        'ILP Policy LINK (Legislation, Statute, or Guidance) ', 'ILP Contact (Name + Email)', 'ILP Webpage LINK']\n",
    "\n",
    "def remove_strings(list, strings_to_be_removed):\n",
    "    for str in strings_to_be_removed:\n",
    "        if str in list:\n",
    "            list.remove(str)\n",
    "    return list \n",
    "\n",
    "def read_all_data(workbook, row_filter_mapping, sheet_name):      \n",
    "    sheet = workbook[sheet_name]    \n",
    "    result = {} \n",
    "    row_num = 1\n",
    "    for row in sheet.rows:\n",
    "        cleanedup_row = []                \n",
    "        if row_num >= 3:            \n",
    "            for cell in row: \n",
    "                link = []\n",
    "                if cell.hyperlink:                    \n",
    "                    parsed = cell.value.split(',')\n",
    "                    if len(parsed) >= 2:                        \n",
    "                        for str in parsed: \n",
    "                            res = re.findall('(http|ftp|https):\\/\\/([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:\\/~+#-]*[\\w@?^=%&\\/~+#-])', str.replace(' ', ''))\n",
    "                            if len(res) > 0:\n",
    "                                link.append(''.join(list(res[0])))\n",
    "                        if len(link) > 0 :\n",
    "                            cleanedup_row.extend(link)\n",
    "                        else:\n",
    "                            cleanedup_row.append(cell.hyperlink.target)\n",
    "                    else:                        \n",
    "                        cleanedup_row.append(cell.hyperlink.target)\n",
    "                elif cell.value and cell.value != '':                             \n",
    "                    #link = re.findall('https?://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+', cell.value)                    \n",
    "                    parsed = cell.value.split(',')                     \n",
    "                    if len(parsed) >= 2: \n",
    "                        for str in parsed:                            \n",
    "                            res = re.findall('(http|ftp|https):\\/\\/([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:\\/~+#-]*[\\w@?^=%&\\/~+#-])', str.replace(' ', ''))\n",
    "                            if len(res) > 0:\n",
    "                                link.append(''.join(list(res[0])))                            \n",
    "                    else: \n",
    "                        res = re.findall('(http|ftp|https):\\/\\/([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:\\/~+#-]*[\\w@?^=%&\\/~+#-])', cell.value)                        \n",
    "                        if len(res) > 0:\n",
    "                            link.append(''.join(list(res[0])))\n",
    "                    if len(link) > 0 :\n",
    "                        cleanedup_row.extend(link)\n",
    "                    else:\n",
    "                        cleanedup_row.append(cell.value.replace('\\n', ','))              \n",
    "            if row_num in row_filter_mapping:                \n",
    "                result[row_filter_mapping[row_num]] = list(set(remove_strings(cleanedup_row[1:], strings_to_be_removed))) \n",
    "        row_num += 1             \n",
    "    return result\n",
    "\n",
    "output = {}\n",
    "workbook = load_workbook(filename='careermap.xlsx')\n",
    "for sheet_name in workbook.sheetnames:\n",
    "    if sheet_name != 'SPECs':       \n",
    "        output[sheet_name] = read_all_data(workbook, row_filter_mapping, sheet_name)        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the scores in scores sheet at https://docs.google.com/spreadsheets/d/19-CWpLqeIrnSa-ytlolUyjq1Y_6FqCSOII-N8cWbRN4/edit#gid=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "us_state_to_abbrev = {\n",
    "    \"Alabama\": \"AL\",\n",
    "    \"Alaska\": \"AK\",\n",
    "    \"Arizona\": \"AZ\",\n",
    "    \"Arkansas\": \"AR\",\n",
    "    \"California\": \"CA\",\n",
    "    \"Colorado\": \"CO\",\n",
    "    \"Connecticut\": \"CT\",\n",
    "    \"Delaware\": \"DE\",\n",
    "    \"Florida\": \"FL\",\n",
    "    \"Georgia\": \"GA\",\n",
    "    \"Hawaii\": \"HI\",\n",
    "    \"Idaho\": \"ID\",\n",
    "    \"Illinois\": \"IL\",\n",
    "    \"Indiana\": \"IN\",\n",
    "    \"Iowa\": \"IA\",\n",
    "    \"Kansas\": \"KS\",\n",
    "    \"Kentucky\": \"KY\",\n",
    "    \"Louisiana\": \"LA\",\n",
    "    \"Maine\": \"ME\",\n",
    "    \"Maryland\": \"MD\",\n",
    "    \"Massachusetts\": \"MA\",\n",
    "    \"Michigan\": \"MI\",\n",
    "    \"Minnesota\": \"MN\",\n",
    "    \"Mississippi\": \"MS\",\n",
    "    \"Missouri\": \"MO\",\n",
    "    \"Montana\": \"MT\",\n",
    "    \"Nebraska\": \"NE\",\n",
    "    \"Nevada\": \"NV\",\n",
    "    \"New Hampshire\": \"NH\",\n",
    "    \"New Jersey\": \"NJ\",\n",
    "    \"New Mexico\": \"NM\",\n",
    "    \"New York \": \"NY\",\n",
    "    \"No Carolina\": \"NC\",\n",
    "    \"No Dakota\": \"ND\",\n",
    "    \"Ohio\": \"OH\",\n",
    "    \"Oklahoma\": \"OK\",\n",
    "    \"Oregon \": \"OR\",\n",
    "    \"Pennsylvania\": \"PA\",\n",
    "    \"Rhode Island\": \"RI\",\n",
    "    \"So Carolina\": \"SC\",\n",
    "    \"So Dakota\": \"SD\",\n",
    "    \"Tennesee\": \"TN\",\n",
    "    \"Texas RB\": \"TX\",\n",
    "    \"Utah\": \"UT\",\n",
    "    \"Vermont\": \"VT\",\n",
    "    \"Virginia\": \"VA\",\n",
    "    \"Washington\": \"WA\",\n",
    "    \"West Virginia\": \"WV\",\n",
    "    \"Wisconsin\": \"WI\",\n",
    "    \"Wyoming\": \"WY\",\n",
    "    \"District of Columbia (DC)\": \"DC\",\n",
    "    \"American Samoa\": \"AS\",\n",
    "    \"Guam\": \"GU\",\n",
    "    \"Northern Mariana Islands\": \"MP\",\n",
    "    \"Puerto Rico\": \"PR\",\n",
    "    \"United States Minor Outlying Islands\": \"UM\",\n",
    "    \"U.S. Virgin Islands\": \"VI\",\n",
    "}\n",
    "\n",
    "scores = {}\n",
    "df = pd.read_excel('scores.xlsx', skiprows=[0])\n",
    "columns = df.columns.tolist()\n",
    "del columns[0]\n",
    "\n",
    "for index, row in df.iterrows():    \n",
    "    scores[us_state_to_abbrev[row['State']]] = {}\n",
    "    for score_name in columns:\n",
    "        scores[us_state_to_abbrev[row['State']]][score_name] = row[score_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the scores and links data for each state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state_name in output:\n",
    "    for key in scores[state_name]:\n",
    "        output[state_name][key] = scores[state_name][key]       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get states polygon coordinates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "states_coordinates = {}\n",
    "\n",
    "f = open('us-state-boundaries.json')\n",
    "data = json.load(f)\n",
    "\n",
    "for rec in data:\n",
    "    states_coordinates[rec['fields']['stusab']] = rec['fields']['st_asgeojson']['coordinates']   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert data to geojson format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "geoJson = {'type': 'FeatureCollection', 'features': []}\n",
    "\n",
    "for state_name in output:\n",
    "    feature = {'type': 'Feature'}\n",
    "    feature['properties'] = output[state_name]\n",
    "    feature['properties']['state_name'] = state_name\n",
    "    feature['geometry'] = {'type': 'Polygon', 'coordinates': states_coordinates[state_name]}\n",
    "    geoJson['features'].append(feature)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the data in geojson format to a file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('states-careers.json', 'w') as f:\n",
    "    json.dump(geoJson, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
